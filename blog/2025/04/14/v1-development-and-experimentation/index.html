
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
        <meta name="author" content="Liam Connell">
      
      
        <link rel="canonical" href="https://liamconnell.github.io/footyai/blog/2025/04/14/v1-development-and-experimentation/">
      
      
      
        <link rel="next" href="../../15/v2-development-and-experimentation/">
      
      
      <link rel="icon" href="../../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.16">
    
    
      
        <title>V1 Development and Experimentation - Footy RL</title>
      
    
    
      <link rel="stylesheet" href="../../../../../assets/stylesheets/main.7e37652d.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#v1-development-and-experimentation" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../../.." title="Footy RL" class="md-header__button md-logo" aria-label="Footy RL" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Footy RL
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              V1 Development and Experimentation
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../.." class="md-tabs__link">
        
  
  
    
  
  Project Home

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    <li class="md-tabs__item md-tabs__item--active">
      <a href="../../../../" class="md-tabs__link">
        
  
  
    
  
  Experiments

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../example_videos/" class="md-tabs__link">
        
  
  
    
  
  Example Videos

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
                
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" hidden>
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../../.." title="Footy RL" class="md-nav__button md-logo" aria-label="Footy RL" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Footy RL
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Project Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      <a href="../../../../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Experiments
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../example_videos/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Example Videos
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
                
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#functional-core" class="md-nav__link">
    <span class="md-ellipsis">
      Functional Core
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#environment" class="md-nav__link">
    <span class="md-ellipsis">
      Environment
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#policy-network" class="md-nav__link">
    <span class="md-ellipsis">
      Policy Network
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-loop" class="md-nav__link">
    <span class="md-ellipsis">
      Training Loop
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Training Loop">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#discounted-reward-computation" class="md-nav__link">
    <span class="md-ellipsis">
      Discounted Reward Computation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#compute" class="md-nav__link">
    <span class="md-ellipsis">
      Compute
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#results" class="md-nav__link">
    <span class="md-ellipsis">
      Results
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusions-and-next-steps" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusions and Next Steps
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Conclusions and Next Steps">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#policy-network-improvements" class="md-nav__link">
    <span class="md-ellipsis">
      Policy Network Improvements
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-algorithm-improvements" class="md-nav__link">
    <span class="md-ellipsis">
      Training Algorithm Improvements
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#end-to-end-tensorization" class="md-nav__link">
    <span class="md-ellipsis">
      End-to-end Tensorization
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
  <div class="md-content md-content--post" data-md-component="content">
    <div class="md-sidebar md-sidebar--post" data-md-component="sidebar" data-md-type="navigation">
      <div class="md-sidebar__scrollwrap">
        <div class="md-sidebar__inner md-post">
          <nav class="md-nav md-nav--primary">
            <div class="md-post__back">
              <div class="md-nav__title md-nav__container">
                <a href="../../../../" class="md-nav__link">
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
                  <span class="md-ellipsis">
                    Back to index
                  </span>
                </a>
              </div>
            </div>
            
            <ul class="md-post__meta md-nav__list">
              <li class="md-nav__item md-nav__item--section">
                <div class="md-post__title">
                  <span class="md-ellipsis">
                    Metadata
                  </span>
                </div>
                <nav class="md-nav">
                  <ul class="md-nav__list">
                    <li class="md-nav__item">
                      <div class="md-nav__link">
                        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 19H5V8h14m-3-7v2H8V1H6v2H5c-1.11 0-2 .89-2 2v14a2 2 0 0 0 2 2h14a2 2 0 0 0 2-2V5a2 2 0 0 0-2-2h-1V1m-1 11h-5v5h5z"/></svg>
                        <time datetime="2025-04-14 00:00:00+00:00" class="md-ellipsis">April 14, 2025</time>
                      </div>
                    </li>
                    
                    
                    
                      
                      <li class="md-nav__item">
                        <div class="md-nav__link">
                          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 20a8 8 0 0 0 8-8 8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8m0-18a10 10 0 0 1 10 10 10 10 0 0 1-10 10C6.47 22 2 17.5 2 12A10 10 0 0 1 12 2m.5 5v5.25l4.5 2.67-.75 1.23L11 13V7z"/></svg>
                          <span class="md-ellipsis">
                            
                              4 min read
                            
                          </span>
                        </div>
                      </li>
                    
                  </ul>
                </nav>
              </li>
            </ul>
            
          </nav>
          
        </div>
      </div>
    </div>
    <article class="md-content__inner md-typeset">
      
        
  




<h1 id="v1-development-and-experimentation">V1 Development and Experimentation<a class="headerlink" href="#v1-development-and-experimentation" title="Permanent link">&para;</a></h1>
<!-- more -->
<h2 id="functional-core">Functional Core<a class="headerlink" href="#functional-core" title="Permanent link">&para;</a></h2>
<p>My initial goal was to set up the environment with a pythonic functional core. I created a <code>GameState</code> object represented all the data at a given point in time, as well as <code>PlayerAction</code> objects. A function of the game state and player actions (from all players on both teams) determined the <code>GameState</code> at the next timestep. </p>
<p>Since the code was in pure python/pydantic and functional, it was easy to test rigorously. I also created a visualizer function that converted an array of game states to an MP4 video. All of my tests wrote out videos so that I could eyeball the logic as needed. </p>
<h2 id="environment">Environment<a class="headerlink" href="#environment" title="Permanent link">&para;</a></h2>
<p>Inspired by OpenAI's <code>Gymnasium</code>, I created an environment with a <code>.step()</code> method that followed the standard interface: it takes in a set of actions for the step, and produces a set of observations for the next timestep, as well as a reward score and basic information about the environment state. </p>
<p>The actions and observations are both flat numpy <code>ndarray</code> types. Even though I was aiming to develop an adversarial multi-agent game, I didnt have any special handling for the two teams in the interface. The actions of each team were simply concatenated together, and the observations were, or course, identical. I would have to handle all the multi-agent logic in my training script later on. </p>
<p>Note that, since I had defined all my game logic in the <code>GameState</code> functional data model, the environment itself was just a thin layer that mediated between <code>ndarray</code> types (that my neural networks would work with) and the native pydantic objects of the data model. </p>
<p>I'll talk about the reward (returned by the <code>.step()</code> method alongside the observation) more later on, but I started with a simple score-based reward. </p>
<h2 id="policy-network">Policy Network<a class="headerlink" href="#policy-network" title="Permanent link">&para;</a></h2>
<p>I created the simplest possible policy network that would support the <code>REINFORCE</code> algorithm. This is simply a neural network that outputs a <code>mu</code> and <code>sigma</code> (each of shape <code>output_size</code>), which will be the parameters of a Normal distribution used for REINFOCE monte carlo sampling. </p>
<h2 id="training-loop">Training Loop<a class="headerlink" href="#training-loop" title="Permanent link">&para;</a></h2>
<p>To begin training, I implemented a basic self-play loop using the REINFORCE algorithm. Two policy networks—one for each team—were initialized independently. On each timestep  both teams produced actions from their policy networks based on the current observation. These actions were sampled from Normal distributions parameterized by the network outputs (<code>mu</code>, <code>sigma</code>), and log-probabilities (<em>log-likelihoods</em> in Bayesian terms) were stored for each timestep to calculate the eventual policy gradient loss.</p>
<h3 id="discounted-reward-computation">Discounted Reward Computation<a class="headerlink" href="#discounted-reward-computation" title="Permanent link">&para;</a></h3>
<p>The environment produces a reward value every time step, but we dont use this directly for gradient descent. </p>
<p>Following the REINFORCE approach, I computed <strong>discounted rewards</strong> at the end of each episode and normalized them, then applied the REINFORCE loss to update each team’s policy network via gradient descent. <strong>Discounted rewards</strong> set the reward at any given timestep to the sum of future rewards, discounted by a decay factor, <code>gamma</code> (typically .99). The intuition here is that an action taken at time <code>t</code> might cause or contribute to a reward at time <code>t+N</code>, and so should be reinforced. </p>
<p>The rewards were handled in a simple zero-sum format: team A received the reward from the environment (after discounted summation and normalization as above), while team B received its negation. </p>
<h2 id="compute">Compute<a class="headerlink" href="#compute" title="Permanent link">&para;</a></h2>
<p>The training loop with 5k iterations of a batch of 64 games could run in about an hour on my macbook's CPU. </p>
<p>Why not use GPU hardware? Well my environment relies on a functional data model in raw python for the game simulation. In other words, whether the model is in the GPU or CPU, something will happen on the CPU every timestep. Putting the model on the GPU would likely make things slower due to data transfer / synchronization time. I put off resolving this until V2. </p>
<h2 id="results">Results<a class="headerlink" href="#results" title="Permanent link">&para;</a></h2>
<p>Because the episode trajectory was driven entirely by the competition between the two agents, their behaviors co-evolved over time. This created an emergent curriculum: early on, the agents moved randomly and struggled to reach the ball, but as training progressed, they began to learn to position, chase, and kick. I rendered short videos every few episodes to qualitatively inspect progress.</p>
<h2 id="conclusions-and-next-steps">Conclusions and Next Steps<a class="headerlink" href="#conclusions-and-next-steps" title="Permanent link">&para;</a></h2>
<p>My agents had certainly learned something - they were able to chase the ball around and seemed to have developed basic skills for scoring and defense. However, there are several areas I would like to improve. </p>
<h3 id="policy-network-improvements">Policy Network Improvements<a class="headerlink" href="#policy-network-improvements" title="Permanent link">&para;</a></h3>
<ul>
<li>The model is quite small and is likely reaching some limits in its ability to learn more advanced tactics. Scaling up is an easy next step. </li>
<li>The model has a very basic architecture, and has almost no special handling for team A vs team B. Adding resonant layers and other architectural tricks will help it learn faster. </li>
</ul>
<h3 id="training-algorithm-improvements">Training Algorithm Improvements<a class="headerlink" href="#training-algorithm-improvements" title="Permanent link">&para;</a></h3>
<ul>
<li>The simplicity of the training loop (no critic, no replay buffer, no batch rollout) helped me iterate quickly and focus on the dynamics of multi-agent self-play. But it also exposed some limitations, especially around sample efficiency and variance in learning. Later versions would introduce improvements here.</li>
</ul>
<h3 id="end-to-end-tensorization">End-to-end Tensorization<a class="headerlink" href="#end-to-end-tensorization" title="Permanent link">&para;</a></h3>
<ul>
<li>As mentioned above, data is being transfered between torch tensors and native python data types. If I fully tensorize the environment and game physics simulators, I can run the entire training loop in torch, speeding things up dramatically. <em>Note: This is a daunting task and would typically require some serious coffee drinking and squinting at the screen for long periods of time, but it also seems like something AI would be good at!</em></li>
</ul>







  
  




  



      
    </article>
  </div>

          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../../../..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.indexes", "navigation.top"], "search": "../../../../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../../../assets/javascripts/bundle.50899def.min.js"></script>
      
    
  </body>
</html>